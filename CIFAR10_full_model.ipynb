{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d17c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchinfo import summary\n",
    "\n",
    "\n",
    "# Torchvision for datasets and transforms\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Data utilities\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Metrics & visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "device = torch.device (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Training transforms: data augmentation + normalization\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),          # Random crop with padding\n",
    "    transforms.RandomHorizontalFlip(),             # Random horizontal flip\n",
    "    transforms.ToTensor(),                         # Convert to tensor\n",
    "    transforms.Normalize(\n",
    "        mean=(0.4914, 0.4822, 0.4465),\n",
    "        std=(0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Test transforms: only normalization\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=(0.4914, 0.4822, 0.4465),\n",
    "        std=(0.2023, 0.1994, 0.2010)\n",
    "    )\n",
    "])\n",
    "\n",
    "# Training set\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=True, download=True, transform=transform_train\n",
    ")\n",
    "trainloader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "# Test set\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data', train=False, download=True, transform=transform_test\n",
    ")\n",
    "testloader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Class names\n",
    "classes = trainset.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "images, labels = next (iter(trainloader))\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "print(labels[:10])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debe0ae3",
   "metadata": {},
   "source": [
    "## Experiment 1: Architecture Comparison\n",
    "\n",
    "This experiment compares three convolutional neural network architectures on the CIFAR-10 dataset:\n",
    "1. A custom Baseline CNN designed from scratch\n",
    "2. ResNet18 adapted for CIFAR-10\n",
    "3. DenseNet121 adapted for CIFAR-10\n",
    "\n",
    "All models are trained using the same data preprocessing, optimizer (Adam), learning rate (0.001),\n",
    "batch size, and number of epochs to isolate the effect of architectural design.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8988b9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class BaselineCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            # Convolutional + ReLU + Pooling\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "\n",
    "            # Flatten and fully connected layers\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "\n",
    "model1 = BaselineCNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model1.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model1.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward\n",
    "        outputs = model1(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model1(images)           # [batch, 10]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "baseline_accuracy = accuracy\n",
    "\n",
    "\n",
    "\n",
    "model1.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model1(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.append(predicted.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – Baseline CNN\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a373272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "class ResNet18_CIFAR(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()  \n",
    "    self.model = models.resnet18(weights = None)\n",
    "    self.model.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size =3, stride = 1, padding = 1, bias = False )\n",
    "    self.model.maxpool = nn.Identity()\n",
    "    self.model.fc = nn.Linear(512, 10)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.model(x) \n",
    "\n",
    "model2 = ResNet18_CIFAR().to(device)\n",
    "\n",
    "    \n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    model2.train()\n",
    "    \n",
    "    for images, labels in trainloader:  # fixed order\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model2(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "model2.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "  for images, labels in testloader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model2(images)\n",
    "    _, predicted = torch.max(outputs,1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item() \n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "resnet_accuracy = accuracy\n",
    "\n",
    "\n",
    "\n",
    "model2.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model2(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.append(predicted.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – ResNet CNN\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84143e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class DenseNet_CIFAR(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = models.densenet121(weights=None)\n",
    "\n",
    "        # Modify first conv layer for CIFAR-10\n",
    "        self.model.features.conv0 = nn.Conv2d(\n",
    "            in_channels=3,\n",
    "            out_channels=64,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "\n",
    "        # Remove initial pooling\n",
    "        self.model.features.pool0 = nn.Identity()\n",
    "\n",
    "        # Modify classifier for 10 classes\n",
    "        self.model.classifier = nn.Linear(\n",
    "            self.model.classifier.in_features, 10\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "\n",
    "model3 = DenseNet_CIFAR().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model3.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 10\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    model3.train()\n",
    "\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model3(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "model3.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model3(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "densenet_accuracy = accuracy\n",
    "\n",
    "\n",
    "\n",
    "model3.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in testloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model3(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_preds.append(predicted.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "\n",
    "\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=classes,\n",
    "            yticklabels=classes)\n",
    "\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix – DenseNet CNN\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970b1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results_exp1 = pd.DataFrame({\n",
    "    \"Model\": [\"Baseline CNN\", \"ResNet18\", \"DenseNet121\"],\n",
    "    \"Test Accuracy (%)\": [\n",
    "        baseline_accuracy,\n",
    "        resnet_accuracy,\n",
    "        densenet_accuracy\n",
    "    ]\n",
    "})\n",
    "\n",
    "results_exp1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743608e1",
   "metadata": {},
   "source": [
    "## Experiment 2: Optimizer Comparison\n",
    "\n",
    "In this experiment, the ResNet18 architecture is fixed while comparing two optimization strategies:\n",
    "Adam and Stochastic Gradient Descent (SGD).\n",
    "\n",
    "The goal is to analyze how optimizer choice affects training convergence and final performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75982960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, num_epochs=10):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images, labels in trainloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / len(trainloader)\n",
    "        train_losses.append(epoch_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "\n",
    "model_adam = ResNet18_CIFAR().to(device)\n",
    "optimizer_adam = optim.Adam(model_adam.parameters(), lr=0.001)\n",
    "\n",
    "loss_adam = train_model(model_adam, optimizer_adam)\n",
    "\n",
    "\n",
    "model_sgd = ResNet18_CIFAR().to(device)\n",
    "optimizer_sgd = optim.SGD(model_sgd.parameters(), lr=0.1, momentum=0.9)\n",
    "\n",
    "loss_sgd = train_model(model_sgd, optimizer_sgd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55057c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(loss_adam, label=\"Adam\")\n",
    "plt.plot(loss_sgd, label=\"SGD\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.title(\"Experiment 2: Optimizer Comparison\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
